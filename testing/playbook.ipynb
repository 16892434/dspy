{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T02:11:11.471673Z",
     "start_time": "2024-11-22T02:11:05.166881Z"
    }
   },
   "source": [
    "import dspy\n",
    "import litellm\n",
    "from optimizer_tester import OptimizerTester\n",
    "\n",
    "API_KEY = \"...\"\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = API_KEY\n",
    "lm = dspy.LM('openai/gpt-4o-mini', api_key=API_KEY)\n",
    "\n",
    "dspy.settings.configure(lm=lm)\n",
    "tester = OptimizerTester(task_model=lm, prompt_model=lm)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-22T02:11:15.642940Z"
    }
   },
   "source": [
    "def test_bootstrap_knn(default_program, trainset, devset, test_name, dataset_name, kwargs):\n",
    "    # initialize your teleprompter (optimizer) here!\n",
    "    teleprompter = dspy.BootstrapKNN(\n",
    "        metric=kwargs[\"metric\"],\n",
    "        embedding=dspy.Embedding(model=\"openai/text-embedding-3-small\", api_key=API_KEY),\n",
    "        max_bootstrapped_demos=64,\n",
    "        max_labeled_demos=16,\n",
    "        max_errors=10,\n",
    "    )\n",
    "\n",
    "    # call your optimizer on the default_program here!\n",
    "    compiled_program = teleprompter.compile(default_program.deepcopy(), trainset=trainset)\n",
    "\n",
    "    # if you wish to tweak any of the outputs to the csv file you can do that here\n",
    "    output = {\n",
    "        \"test_name\": f\"bootstrap-knn-{dataset_name}-{test_name}\",\n",
    "    }\n",
    "\n",
    "    # return the compiled program and modified output (or empty dict if no changes made)\n",
    "    return compiled_program, output\n",
    "\n",
    "tester.test_optimizer_default(\n",
    "    test_bootstrap_knn,\n",
    "    datasets=[\n",
    "        # \"hotpotqa\",\n",
    "        # \"hotpotqa_conditional\",\n",
    "        \"tweet\",\n",
    "        # \"tweet_metric\",\n",
    "        # \"heart_disease\",\n",
    "        # \"hover_retrieve_discrete\",\n",
    "    ]\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing  Optimizers on tweet ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated, underperform, and are about to be deleted. ***\n",
      " \t\tYou are using the client GPT3, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n",
      "100%|██████████| 200/200 [00:03<00:00, 63.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 199 examples for up to 1 rounds, amounting to 200 attempts.\n",
      "Optimized train score...\n",
      "Average Metric: 7.33 / 200 (3.7%): 100%|██████████| 200/200 [17:02<00:00,  5.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 19:28:39 INFO dspy.evaluate.evaluate: Average Metric: 7.333333333333333 / 200 (3.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized dev score...\n",
      "Average Metric: 0.00 / 100 (0.0%): 100%|██████████| 100/100 [18:28<00:00, 11.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 19:47:08 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 100 (0.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized test score...\n",
      "Average Metric: 0.00 / 49 (0.0%):  24%|██▍       | 49/200 [12:34<26:08, 10.39s/it]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

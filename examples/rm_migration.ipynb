{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{DSPy.RM Migration - TBD}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Querying ColBERTv2 \n",
    "\n",
    "import requests\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from dspy import RM, Retrieve, Embedder\n",
    "from dspy.primitives.prediction import Prediction\n",
    "\n",
    "def colbert_search_function(query: str, k: int, url: str, post_requests: bool = False) -> List[Dict[str, Any]]:\n",
    "    if post_requests:\n",
    "        headers = {\"Content-Type\": \"application/json; charset=utf-8\"}\n",
    "        payload = {\"query\": query, \"k\": k}\n",
    "        res = requests.post(url, json=payload, headers=headers, timeout=10)\n",
    "    else:\n",
    "        payload = {\"query\": query, \"k\": k}\n",
    "        res = requests.get(url, params=payload, timeout=10)\n",
    "    \n",
    "    res.raise_for_status()\n",
    "    topk = res.json()[\"topk\"][:k]\n",
    "    topk = [{**doc, \"long_text\": doc.get(\"text\", \"\")} for doc in topk]\n",
    "    return topk\n",
    "\n",
    "def colbert_result_formatter(results: List[Dict[str, Any]]) -> Prediction:\n",
    "    passages = [doc[\"long_text\"] for doc in results]\n",
    "    return Prediction(passages=passages)\n",
    "\n",
    "colbert_url = \"http://20.102.90.50:2017/wiki17_abstracts\"\n",
    "\n",
    "colbert_rm = RM(\n",
    "    search_function=colbert_search_function,\n",
    "    result_formatter=colbert_result_formatter,\n",
    "    url=colbert_url,\n",
    "    post_requests=False\n",
    ")\n",
    "\n",
    "retrieve = Retrieve(rm=colbert_rm, k=10)\n",
    "query_text = \"Example query text\"\n",
    "results = retrieve(query_text)\n",
    "print(results.passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Querying Databricks Mosaic AI Vector Search \n",
    "\n",
    "#client setup\n",
    "databricks_token = os.environ.get(\"DATABRICKS_TOKEN\")\n",
    "databricks_endpoint = os.environ.get(\"DATABRICKS_HOST\")\n",
    "databricks_client = WorkspaceClient(host=databricks_endpoint, token=databricks_token)\n",
    "\n",
    "#custom logic for querying and sorting the docs\n",
    "def databricks_search_function(\n",
    "    query,\n",
    "    k,\n",
    "    index_name,\n",
    "    columns,\n",
    "    query_type='ANN',\n",
    "    filters_json=None,\n",
    "    client=None\n",
    "):\n",
    "    results = client.vector_search_indexes.query(\n",
    "        index_name=index_name,\n",
    "        query_type=query_type,\n",
    "        query_text=query,\n",
    "        num_results=k,\n",
    "        columns=columns,\n",
    "        filters_json=filters_json,\n",
    "    ).as_dict()\n",
    "\n",
    "    items = []\n",
    "    col_names = [column[\"name\"] for column in results[\"manifest\"][\"columns\"]]\n",
    "    for data_row in results[\"result\"][\"data_array\"]:\n",
    "        item = {col_name: val for col_name, val in zip(col_names, data_row)}\n",
    "        items.append(item)\n",
    "    sorted_docs = sorted(items, key=lambda x: x[\"score\"], reverse=True)\n",
    "    return sorted_docs\n",
    "\n",
    "def databricks_result_formatter(results) -> Prediction:\n",
    "    passages = [doc['some_text_column'] for doc in results] \n",
    "    return Prediction(passages=passages)\n",
    "\n",
    "databricks_rm = RM(\n",
    "    search_function=databricks_search_function,\n",
    "    result_formatter=databricks_result_formatter,\n",
    "    client=databricks_client,\n",
    "    index_name='your_index_name',\n",
    "    columns=['id', 'some_text_column'],\n",
    "    filters_json=None\n",
    ")\n",
    "\n",
    "retrieve = Retrieve(rm=databricks_rm, k=3)\n",
    "results = retrieve(\"Example query text\")\n",
    "print(results.passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Querying Deeplake Vector Store\n",
    "\n",
    "embedder = Embedder()\n",
    "\n",
    "deeplake_vectorstore_name = 'vectorstore_name'\n",
    "deeplake_client = deeplake.VectorStore(\n",
    "    path=deeplake_vectorstore_name,\n",
    "    embedding_function=embedder\n",
    ")\n",
    "\n",
    "def deeplake_search_function(query, k, client=None):\n",
    "    results = client.search(query, k=k)\n",
    "    return results\n",
    "\n",
    "def deeplake_result_formatter(results) -> Prediction:\n",
    "    passages = [doc['text'] for doc in results['documents']]\n",
    "    return Prediction(passages=passages)\n",
    "\n",
    "\n",
    "deeplake_rm = RM(\n",
    "    embedder=embedder,\n",
    "    search_function=deeplake_search_function,\n",
    "    result_formatter=deeplake_result_formatter,\n",
    "    client=deeplake_client\n",
    ")\n",
    "\n",
    "retrieve = Retrieve(rm=deeplake_rm, k=3)\n",
    "results = retrieve(\"some text\")\n",
    "print(results.passages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

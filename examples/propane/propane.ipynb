{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import tiktoken\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Goal is to take a sequence of tokens, and return the topk tokens at position i\n",
    "# Such that the tokens maximize the negative gradient of the loss function across the entire sequence\n",
    "\n",
    "# Initial sequence\n",
    "\n",
    "def setup_model_and_tokenizer():\n",
    "    # Initialize model and tokenizer\n",
    "    model_name = \"lmsys/vicuna-7b-v1.5\"\n",
    "    chat_template = \"{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = 'A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user\\\\'s questions.' %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 %}{{ system_message }}{% endif %}{% if message['role'] == 'user' %}{{ ' USER: ' + message['content'].strip() }}{% elif message['role'] == 'assistant' %}{{ ' ASSISTANT: ' + message['content'].strip() + eos_token }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ ' ASSISTANT:' }}{% endif %}\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, chat_template=chat_template)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    return model, tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be8cfcfb5b34bbcbfb1f7eaa2ac4a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/dspy-propane/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/dspy-propane/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/dspy-propane/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/dspy-propane/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "model, tokenizer = setup_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_tokens(model, tokenizer, sequence, position, top_k=5):\n",
    "    # Tokenize the input sequence\n",
    "    messages = [{\"role\": \"user\", \"content\": sequence}]\n",
    "    inputs = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs.to(model.device)\n",
    "    \n",
    "    # Create a copy of input_ids that requires gradient\n",
    "    input_embeds = model.get_input_embeddings()(input_ids)\n",
    "    input_embeds.requires_grad_(True)\n",
    "    input_embeds.retain_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(inputs_embeds=input_embeds)\n",
    "    logits = outputs.logits\n",
    "    \n",
    "    # Calculate loss (we'll use the current token prediction loss)\n",
    "    # Don't shift the logits/labels since we want current token prediction\n",
    "    loss = F.cross_entropy(logits.view(-1, logits.size(-1)),\n",
    "                          input_ids.view(-1))\n",
    "    \n",
    "    # Calculate gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Get gradients at the specified position\n",
    "    position_gradients = input_embeds.grad[0, position]\n",
    "    \n",
    "    # Get the token embeddings\n",
    "    token_embeddings = model.get_input_embeddings().weight\n",
    "    \n",
    "    # Calculate similarity between position gradients and all token embeddings\n",
    "    similarities = torch.matmul(token_embeddings, position_gradients)\n",
    "    \n",
    "    # Get top-k tokens that maximize the negative gradient\n",
    "    top_values, top_indices = torch.topk(-similarities, k=top_k)\n",
    "    \n",
    "    # Convert token ids to tokens\n",
    "    top_tokens = [tokenizer.decode([idx.item()]) for idx in top_indices]\n",
    "    \n",
    "    return top_tokens, list(map(lambda x: -x, top_values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sequence: What is the capital of France?\n",
      "Converting to chatml format\n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: What is the capital of France? ASSISTANT:\n",
      "\n",
      "Tokenized sequence length: 46\n",
      "Analyzing gradient-based importance for each position...\n",
      "\n",
      "Position 0 (current token: '<s>')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'A', Score: -0.6602\n",
      "  Token: '\n",
      "', Score: -0.2008\n",
      "  Token: 'А', Score: -0.1494\n",
      "  Token: 'A', Score: -0.1008\n",
      "  Token: 'The', Score: -0.0703\n",
      "\n",
      "Position 1 (current token: 'A')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'disag', Score: -0.0797\n",
      "  Token: 'indic', Score: -0.0774\n",
      "  Token: 'compet', Score: -0.0681\n",
      "  Token: 'autonom', Score: -0.0680\n",
      "  Token: 'kilom', Score: -0.0672\n",
      "\n",
      "Position 2 (current token: 'chat')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'eigh', Score: -0.0774\n",
      "  Token: 'боль', Score: -0.0742\n",
      "  Token: 'comprom', Score: -0.0715\n",
      "  Token: 'wob', Score: -0.0713\n",
      "  Token: 'overlap', Score: -0.0712\n",
      "\n",
      "Position 3 (current token: 'between')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: '定', Score: -0.0510\n",
      "  Token: 'р', Score: -0.0499\n",
      "  Token: 'し', Score: -0.0492\n",
      "  Token: 'get', Score: -0.0490\n",
      "  Token: 'U', Score: -0.0489\n",
      "\n",
      "Position 4 (current token: 'a')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'odd', Score: -0.0472\n",
      "  Token: 'cur', Score: -0.0356\n",
      "  Token: 'keeping', Score: -0.0322\n",
      "  Token: 'Dic', Score: -0.0322\n",
      "  Token: 'Curt', Score: -0.0321\n",
      "\n",
      "Position 5 (current token: 'curious')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'Enum', Score: -0.0577\n",
      "  Token: 'javafx', Score: -0.0555\n",
      "  Token: 'GitHub', Score: -0.0549\n",
      "  Token: 'игра', Score: -0.0549\n",
      "  Token: '<?', Score: -0.0547\n",
      "\n",
      "Position 6 (current token: 'user')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'gt', Score: -0.0778\n",
      "  Token: 'ocation', Score: -0.0741\n",
      "  Token: 'zer', Score: -0.0728\n",
      "  Token: 'bit', Score: -0.0726\n",
      "  Token: 'ucker', Score: -0.0723\n",
      "\n",
      "Position 7 (current token: 'and')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'ę', Score: -0.0273\n",
      "  Token: 'ą', Score: -0.0271\n",
      "  Token: 'een', Score: -0.0268\n",
      "  Token: 'a', Score: -0.0266\n",
      "  Token: 'ра', Score: -0.0261\n",
      "\n",
      "Position 8 (current token: 'an')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'lyph', Score: -0.0351\n",
      "  Token: 'artific', Score: -0.0337\n",
      "  Token: 'artifact', Score: -0.0336\n",
      "  Token: '删', Score: -0.0327\n",
      "  Token: 'сут', Score: -0.0326\n",
      "\n",
      "Position 9 (current token: 'artificial')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'ि', Score: -0.0409\n",
      "  Token: 'cted', Score: -0.0396\n",
      "  Token: 'lib', Score: -0.0348\n",
      "  Token: 'ி', Score: -0.0345\n",
      "  Token: 'vt', Score: -0.0340\n",
      "\n",
      "Position 10 (current token: 'intelligence')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'serial', Score: -0.0426\n",
      "  Token: 'sert', Score: -0.0408\n",
      "  Token: 'Sund', Score: -0.0378\n",
      "  Token: 'jax', Score: -0.0371\n",
      "  Token: 'Santa', Score: -0.0367\n",
      "\n",
      "Position 11 (current token: 'assistant')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'ly', Score: -0.1072\n",
      "  Token: '�', Score: -0.1064\n",
      "  Token: '�', Score: -0.1046\n",
      "  Token: '�', Score: -0.1045\n",
      "  Token: '�', Score: -0.1043\n",
      "\n",
      "Position 12 (current token: '.')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'и', Score: -0.0426\n",
      "  Token: 'di', Score: -0.0406\n",
      "  Token: '�', Score: -0.0394\n",
      "  Token: 'не', Score: -0.0365\n",
      "  Token: 'an', Score: -0.0359\n",
      "\n",
      "Position 13 (current token: 'The')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'aby', Score: -0.0527\n",
      "  Token: 'el', Score: -0.0464\n",
      "  Token: 'ny', Score: -0.0462\n",
      "  Token: 'AI', Score: -0.0437\n",
      "  Token: 'Ball', Score: -0.0433\n",
      "\n",
      "Position 14 (current token: 'assistant')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'giv', Score: -0.0571\n",
      "  Token: 'Give', Score: -0.0560\n",
      "  Token: 'glory', Score: -0.0534\n",
      "  Token: 'accum', Score: -0.0532\n",
      "  Token: 'beg', Score: -0.0506\n",
      "\n",
      "Position 15 (current token: 'gives')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'great', Score: -0.0321\n",
      "  Token: 'evil', Score: -0.0292\n",
      "  Token: 'tal', Score: -0.0285\n",
      "  Token: 'bad', Score: -0.0277\n",
      "  Token: 'ree', Score: -0.0276\n",
      "\n",
      "Position 16 (current token: 'helpful')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: '：', Score: -0.0565\n",
      "  Token: 'der', Score: -0.0552\n",
      "  Token: '・', Score: -0.0544\n",
      "  Token: 'в', Score: -0.0544\n",
      "  Token: 'ein', Score: -0.0543\n",
      "\n",
      "Position 17 (current token: ',')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'Mira', Score: -0.0170\n",
      "  Token: 'tta', Score: -0.0167\n",
      "  Token: 'Ş', Score: -0.0165\n",
      "  Token: 'ktur', Score: -0.0162\n",
      "  Token: 'ὶ', Score: -0.0161\n",
      "\n",
      "Position 18 (current token: 'detailed')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: '：', Score: -0.0453\n",
      "  Token: '\").', Score: -0.0447\n",
      "  Token: '(!', Score: -0.0438\n",
      "  Token: 'în', Score: -0.0433\n",
      "  Token: '\"></', Score: -0.0433\n",
      "\n",
      "Position 19 (current token: ',')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: '￼', Score: -0.0292\n",
      "', Score: -0.0291\n",
      "', Score: -0.0282\n",
      "', Score: -0.0279\n",
      "  Token: '[,', Score: -0.0278\n",
      "\n",
      "Position 20 (current token: 'and')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'По', Score: -0.0279\n",
      "  Token: 'ent', Score: -0.0242\n",
      "  Token: 'Pologne', Score: -0.0235\n",
      "  Token: 'по', Score: -0.0229\n",
      "  Token: 'Pr', Score: -0.0227\n",
      "\n",
      "Position 21 (current token: 'pol')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'She', Score: -0.0159\n",
      "  Token: 'Night', Score: -0.0157\n",
      "  Token: 'Ш', Score: -0.0154\n",
      "  Token: 'Hann', Score: -0.0150\n",
      "  Token: '’', Score: -0.0149\n",
      "\n",
      "Position 22 (current token: 'ite')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'with', Score: -0.0112\n",
      "  Token: 'from', Score: -0.0111\n",
      "  Token: 'into', Score: -0.0101\n",
      "  Token: 'on', Score: -0.0096\n",
      "  Token: 'than', Score: -0.0092\n",
      "\n",
      "Position 23 (current token: 'answers')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: '[-', Score: -0.0449\n",
      "  Token: '$[', Score: -0.0441\n",
      "  Token: '\"/', Score: -0.0439\n",
      "  Token: '=(', Score: -0.0425\n",
      "  Token: '(\"/', Score: -0.0424\n",
      "\n",
      "Position 24 (current token: 'to')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: ' ', Score: -0.0561\n",
      "  Token: '$\\{', Score: -0.0551\n",
      "  Token: '$[', Score: -0.0543\n",
      "  Token: '\"[', Score: -0.0527\n",
      "  Token: '\\\"', Score: -0.0526\n",
      "\n",
      "Position 25 (current token: 'the')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'didn', Score: -0.0119\n",
      "  Token: 'won', Score: -0.0084\n",
      "  Token: 'couldn', Score: -0.0069\n",
      "  Token: 'wasn', Score: -0.0067\n",
      "  Token: 'don', Score: -0.0063\n",
      "\n",
      "Position 26 (current token: 'user')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'RIG', Score: -0.0383\n",
      "  Token: 'н', Score: -0.0368\n",
      "  Token: 'u', Score: -0.0366\n",
      "  Token: 'ület', Score: -0.0365\n",
      "  Token: 'punkt', Score: -0.0363\n",
      "\n",
      "Position 27 (current token: ''')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: ''@', Score: -0.0201\n",
      "  Token: 'ˆ', Score: -0.0195\n",
      "  Token: '调', Score: -0.0194\n",
      "  Token: '\\_', Score: -0.0194\n",
      "  Token: '\".$', Score: -0.0192\n",
      "\n",
      "Position 28 (current token: 's')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'dinner', Score: -0.0083\n",
      "  Token: 'an', Score: -0.0080\n",
      "  Token: 'A', Score: -0.0077\n",
      "  Token: 'д', Score: -0.0076\n",
      "  Token: 'Д', Score: -0.0075\n",
      "\n",
      "Position 29 (current token: 'questions')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: ' ', Score: -0.0913\n",
      "  Token: 'были', Score: -0.0899\n",
      "  Token: 'для', Score: -0.0892\n",
      "  Token: ' ', Score: -0.0886\n",
      "  Token: 'het', Score: -0.0886\n",
      "\n",
      "Position 30 (current token: '.')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'NS', Score: -0.0297\n",
      "  Token: 'MM', Score: -0.0272\n",
      "  Token: 'SP', Score: -0.0246\n",
      "  Token: 'LM', Score: -0.0235\n",
      "  Token: 'LT', Score: -0.0227\n",
      "\n",
      "Position 31 (current token: 'US')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'opol', Score: -0.0509\n",
      "  Token: 'esk', Score: -0.0490\n",
      "  Token: 'emon', Score: -0.0478\n",
      "  Token: 'User', Score: -0.0471\n",
      "  Token: 'GB', Score: -0.0453\n",
      "\n",
      "Position 32 (current token: 'ER')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: '’', Score: -0.0053\n",
      "  Token: ''', Score: -0.0002\n",
      "  Token: 'm', Score: -0.0000\n",
      "  Token: '9', Score: -0.0000\n",
      "  Token: 'h', Score: -0.0000\n",
      "\n",
      "Position 33 (current token: ':')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'Jac', Score: -0.0215\n",
      "  Token: 'Burg', Score: -0.0211\n",
      "  Token: 'agine', Score: -0.0205\n",
      "  Token: 'Mey', Score: -0.0201\n",
      "  Token: 'iful', Score: -0.0199\n",
      "\n",
      "Position 34 (current token: 'What')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: '_', Score: -0.0246\n",
      "  Token: '�', Score: -0.0240\n",
      "  Token: ''', Score: -0.0234\n",
      "  Token: '-', Score: -0.0230\n",
      "  Token: '（', Score: -0.0230\n",
      "\n",
      "Position 35 (current token: 'is')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: ' ', Score: -0.0482\n",
      "  Token: '\\}', Score: -0.0473\n",
      "  Token: ':@\"', Score: -0.0468\n",
      "  Token: ''}', Score: -0.0468\n",
      "  Token: '-->', Score: -0.0465\n",
      "\n",
      "Position 36 (current token: 'the')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'central', Score: -0.0363\n",
      "  Token: 'Haupt', Score: -0.0354\n",
      "  Token: 'う', Score: -0.0348\n",
      "  Token: 'primeira', Score: -0.0347\n",
      "  Token: 'Cho', Score: -0.0320\n",
      "\n",
      "Position 37 (current token: 'capital')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: ' ', Score: -0.0382\n",
      "  Token: 'Park', Score: -0.0376\n",
      "  Token: 'Charles', Score: -0.0370\n",
      "  Token: 'Pot', Score: -0.0366\n",
      "  Token: 'Kar', Score: -0.0365\n",
      "\n",
      "Position 38 (current token: 'of')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'streets', Score: -0.0242\n",
      "  Token: 'city', Score: -0.0241\n",
      "  Token: '真', Score: -0.0231\n",
      "  Token: 'reet', Score: -0.0227\n",
      "  Token: 'country', Score: -0.0227\n",
      "\n",
      "Position 39 (current token: 'France')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: ':', Score: -0.0978\n",
      "  Token: '-', Score: -0.0754\n",
      "  Token: '–', Score: -0.0665\n",
      "  Token: '•', Score: -0.0602\n",
      "  Token: ';', Score: -0.0600\n",
      "\n",
      "Position 40 (current token: '?')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'an', Score: -0.1083\n",
      "  Token: 'a', Score: -0.0960\n",
      "  Token: 'ɡ', Score: -0.0811\n",
      "  Token: 'ned', Score: -0.0764\n",
      "  Token: 'á', Score: -0.0725\n",
      "\n",
      "Position 41 (current token: 'A')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'Edd', Score: -0.0256\n",
      "  Token: 'д', Score: -0.0253\n",
      "  Token: 'Ell', Score: -0.0237\n",
      "  Token: 'Ét', Score: -0.0237\n",
      "  Token: 'kk', Score: -0.0233\n",
      "\n",
      "Position 42 (current token: 'SS')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'Исто', Score: -0.0478\n",
      "  Token: 'Dist', Score: -0.0466\n",
      "  Token: 'Imp', Score: -0.0420\n",
      "  Token: 'Hist', Score: -0.0399\n",
      "  Token: 'Import', Score: -0.0397\n",
      "\n",
      "Position 43 (current token: 'IST')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 'ICATION', Score: -0.0207\n",
      "  Token: 'ITY', Score: -0.0200\n",
      "  Token: 'IAL', Score: -0.0195\n",
      "  Token: 'IES', Score: -0.0186\n",
      "  Token: 'MENT', Score: -0.0186\n",
      "\n",
      "Position 44 (current token: 'ANT')\n",
      "Top replacement tokens by gradient magnitude:\n",
      "  Token: 's', Score: -0.0045\n",
      "  Token: 'DS', Score: -0.0045\n",
      "  Token: 'Y', Score: -0.0039\n",
      "  Token: 'VD', Score: -0.0037\n",
      "  Token: 'WN', Score: -0.0035\n",
      "\n",
      "Position 45 (current token: ':')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 45 is out of bounds for dimension 1 with size 45",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m tokens_at_pos \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode([tokens[i]])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPosition \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (current token: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokens_at_pos\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m top_tokens, importance_scores \u001b[38;5;241m=\u001b[39m \u001b[43mget_gradient_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop replacement tokens by gradient magnitude:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token, score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(top_tokens, importance_scores):\n",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m, in \u001b[0;36mget_gradient_tokens\u001b[0;34m(model, tokenizer, sequence, position, top_k)\u001b[0m\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Get gradients at the specified position\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m position_gradients \u001b[38;5;241m=\u001b[39m \u001b[43minput_embeds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Get the token embeddings\u001b[39;00m\n\u001b[1;32m     28\u001b[0m token_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_input_embeddings()\u001b[38;5;241m.\u001b[39mweight\n",
      "\u001b[0;31mIndexError\u001b[0m: index 45 is out of bounds for dimension 1 with size 45"
     ]
    }
   ],
   "source": [
    "\n",
    "sequence = \"What is the capital of France?\"\n",
    "\n",
    "print(f\"Analyzing sequence: {sequence}\")\n",
    "\n",
    "print(\"Converting to chatml format\")\n",
    "messages = [{\"role\": \"user\", \"content\": sequence}]\n",
    "inputs = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "# Get tokenized sequence length\n",
    "tokens = tokenizer.encode(inputs, return_tensors=\"pt\")[0]\n",
    "seq_length = len(tokens)\n",
    "\n",
    "print(f\"\\nTokenized sequence length: {seq_length}\")\n",
    "print(\"Analyzing gradient-based importance for each position...\")\n",
    "# only change the tokens that are a part of the prompt\n",
    "prompt_tokens = tokenizer.encode(sequence, return_tensors=\"pt\")[0]\n",
    "# Analyze each position\n",
    "for i in range(seq_length - 1):\n",
    "    tokens_at_pos = tokenizer.decode([tokens[i]])\n",
    "    print(f\"\\nPosition {i} (current token: '{tokens_at_pos}')\")\n",
    "    \n",
    "    top_tokens, importance_scores = get_gradient_tokens(model, tokenizer, sequence, i)\n",
    "    \n",
    "    print(\"Top replacement tokens by gradient magnitude:\")\n",
    "    for token, score in zip(top_tokens, importance_scores):\n",
    "        print(f\"  Token: '{token}', Score: {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
